{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap 9: Convolutional Networks\n",
    "**Convolutional networks (CNNs)**: a specialized kind of neural network for processing data that has a known, grid-like topology.\n",
    "Ex: time-series data - 1D gird, images - 2D grid.\n",
    "\n",
    "Convolutional networks are simply neural networks that use **convolution** in place of general matrix multiplication in at least one of their layers.\n",
    "\n",
    "## The Convolution Operation\n",
    "Convolution is an operation on two functions of a realvalued argument:\n",
    "\n",
    "$s(t) = \\int x(a)w(t − a)da = (x * w)(t)$\n",
    "\n",
    "- First argument: x - **input**\n",
    "\n",
    "- Second argument: w - **kernel**\n",
    "\n",
    "- Ouput: **feature map**\n",
    "\n",
    "Discrete convolution:\n",
    "\n",
    "$s(t) = (x ∗ w)(t) = \\sum^\\infty_{a=-\\infty} = x(a)w(t − a)$\n",
    "\n",
    "We often use convolutions over more than one axis at a time. Ex: 2D image I as input, 2D kernel K\n",
    "\n",
    "$S(i, j) = (I ∗ K)(i, j) = \\sum_m \\sum_n I(m, n)K(i − m, j − n)$\n",
    "\n",
    "Convolution is commutative\n",
    "\n",
    "-> $S(i, j) = (K ∗ I)(i, j) = \\sum_m \\sum_n I(i − m, j − n)K(m, n)$\n",
    "\n",
    "**Cross-correlation**, which is the same as convolution but without flipping the kernel:\n",
    "\n",
    "$S(i, j) = (I ∗ K)(i, j) = \\sum_m \\sum_n I(i + m, j + n)K(m, n)$\n",
    "\n",
    "![convolution][convolution]\n",
    "Many machine learning libraries implement cross-correlation but call it convolution.\n",
    "\n",
    "Discrete convolution can be viewed as multiplication by a matrix. However, the matrix has several entries constrained to be equal to other entries. \n",
    "\n",
    "## Motivation\n",
    "Convolution leverages three important ideas that can help improve a ML system: \n",
    "- sparse interactions (sparse connectivity or sparse weights)\n",
    "- parameter sharing\n",
    "- equivariant representations\n",
    "\n",
    "### Sparse interactions\n",
    "making kernel smaller than the input \n",
    "Ex: The input image might have thousands or millions of pixels, but we can detect small, meaningful features such as edges with kernels that occupy only tens or hundreds of pixels.\n",
    "\n",
    "**Advantage**:\n",
    "- need to store fewer parameters, which both reduces the memory requirements of the model and improves its statistical efficiency.\n",
    "- computing the output requires fewer operations. \n",
    "\n",
    "-> These improvements in efficiency are usually quite large\n",
    "\n",
    "![sparse-interaction][sparse-interaction]\n",
    "\n",
    "### Parameter sharing\n",
    "Parameter sharing refers to using the same parameter for more than one function in a model.\n",
    "\n",
    "In a convolutional neural net, each member of the kernel is used at every position of the input \n",
    "\n",
    "-> rather than learning a separate set of parameter for every location, we learn only one set.\n",
    "\n",
    "Convolution is thus dramatically more efficient than dense matrix multiplication in terms of the memory equirements\n",
    "and statistical efficiency. \n",
    "\n",
    "How sparse connectivity and parameter sharing can dramatically improve the efficiency of a linear function for detecting edges in an image: \n",
    "![edge-detection][edge-detection]\n",
    "\n",
    "### Equivariance\n",
    "The particular form of parameter sharing leads to equivariance to translation.\n",
    "\n",
    "a function is equivariant means that if the input changes, the output changes in the same way.\n",
    "\n",
    "A function $f(x)$ is equivariant to a function $g$ if $f (g (x))=g (f (x))$ \n",
    "\n",
    "if we let $g$ be any function that translates the input, i.e., shifts it, then the convolution function is equivariant to $g$\n",
    "\n",
    "Convolution is not naturally equivariant to some other transformations, such as changes in the scale or rotation of an image.\n",
    "\n",
    "Some kinds of data cannot be processed by neural networks defined by matrix multiplication with a fixed-shape matrix. Convolution enables processing of some of these kinds of data.\n",
    "\n",
    "## Pooling \n",
    "A typical layer of a convolutional network consists of three stages \n",
    "1. The layer performs several convolutions in parallel to produce a set of linear activations\n",
    "2. each linear activation is run through a nonlinear activation function, such as the rectified linear activation function (detector stage)\n",
    "3. we use a **pooling function** to modify the output of the layer further\n",
    "\n",
    "A pooling function replaces the output of the net at a certain location with a summary statistic of the nearby outputs.\n",
    "\n",
    "-> Pooling helps to make the representation become approximately invariant to small translations of the input.\n",
    "\n",
    "Invariance to local translation can be a very useful property if we care more about whether some feature is present than exactly where it is.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Convolution and Pooling as an Infinitely Strong Prior\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## The Neuroscientific Basis for Convolutional Networks\n",
    "\n",
    "Convolutional networks: \n",
    "- biologically inspired AI\n",
    "- key design principles drawn from neuroscience\n",
    "- begin with neuroscientific experiments \n",
    "        -  David Hubel and Torsten Wiesel: basic facts about how the mammalian vision system works -> Nobel prize\n",
    "            - recording the activity of individual neurons in cats.\n",
    "            - observed how neurons in the cat’s brain responded to images projected in precise locations on a screen in front of the cat.\n",
    "        - ->  neurons in the early visual system responded most strongly to very specific patterns of light, such as precisely oriented bars, but responded hardly at all to other patterns.\n",
    "       \n",
    "we focus on a part of the brain called V1, also known as the primary visual cortex\n",
    "![V1](v1.jpg)\n",
    "\n",
    "V1 is the first area of the brain that begins to perform significantly advanced processing of visual input.\n",
    "\n",
    "Images -> light -> retina (perform some simple preprocessing of the image but do not substantially alter the way it is represented.)\n",
    "\n",
    "A convolutional network layer is designed to capture three properties of V1:\n",
    "- V1 is arranged in a spatial map (bản đồ không gian). It actually has a 2D structure mirroring the structure of the image in the retina\n",
    "- V1 contains many **simple cells** and **complex cells**\n",
    "- \"grandmother\" cells have been shown to actually exist in the human brain, in a region called the medial temporal lobe \n",
    "\n",
    "There are many differences between convolutional networks and the mammalian vision system:\n",
    "- The human eye is mostly very low resolution, except for a tiny patch called the fovea.  Most convolutional networks actually receive large full resolution photographs as input.\n",
    "- Convolutional networks are purely visual (not include mood or thoughs,...)\n",
    "- The human visual system does much more than just recognize objects\n",
    "\n",
    "Reverse correlation shows us that most V1 cells have weights that are described by Gabor functions.\n",
    "\n",
    "The response of a simple cell to an image:\n",
    "\n",
    "$s(I) = \\sum_{x \\in \\mathcal{X}} \\sum_{y \\in \\mathcal{Y}} w(x, y) I(x, y)$\n",
    "[convolution]: convolution.jpg\n",
    "[sparse-interaction]: sparse-interaction.png\n",
    "[edge-detection]: edge-detection.png"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
